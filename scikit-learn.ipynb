{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# Load the Iris dataset\n",
    "data = load_iris()\n",
    "X = data.data  # Features (lo que entra en nuestro modelo estadistico, en nuestra funcion)\n",
    "y = data.target  # Target variable (variable dependiente) (lo que pretendemos predecir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[5.1, 3.5, 1.4, 0.2],\n",
       "        [4.9, 3. , 1.4, 0.2],\n",
       "        [4.7, 3.2, 1.3, 0.2],\n",
       "        [4.6, 3.1, 1.5, 0.2],\n",
       "        [5. , 3.6, 1.4, 0.2],\n",
       "        [5.4, 3.9, 1.7, 0.4],\n",
       "        [4.6, 3.4, 1.4, 0.3],\n",
       "        [5. , 3.4, 1.5, 0.2],\n",
       "        [4.4, 2.9, 1.4, 0.2],\n",
       "        [4.9, 3.1, 1.5, 0.1],\n",
       "        [5.4, 3.7, 1.5, 0.2],\n",
       "        [4.8, 3.4, 1.6, 0.2],\n",
       "        [4.8, 3. , 1.4, 0.1],\n",
       "        [4.3, 3. , 1.1, 0.1],\n",
       "        [5.8, 4. , 1.2, 0.2],\n",
       "        [5.7, 4.4, 1.5, 0.4],\n",
       "        [5.4, 3.9, 1.3, 0.4],\n",
       "        [5.1, 3.5, 1.4, 0.3],\n",
       "        [5.7, 3.8, 1.7, 0.3],\n",
       "        [5.1, 3.8, 1.5, 0.3],\n",
       "        [5.4, 3.4, 1.7, 0.2],\n",
       "        [5.1, 3.7, 1.5, 0.4],\n",
       "        [4.6, 3.6, 1. , 0.2],\n",
       "        [5.1, 3.3, 1.7, 0.5],\n",
       "        [4.8, 3.4, 1.9, 0.2],\n",
       "        [5. , 3. , 1.6, 0.2],\n",
       "        [5. , 3.4, 1.6, 0.4],\n",
       "        [5.2, 3.5, 1.5, 0.2],\n",
       "        [5.2, 3.4, 1.4, 0.2],\n",
       "        [4.7, 3.2, 1.6, 0.2],\n",
       "        [4.8, 3.1, 1.6, 0.2],\n",
       "        [5.4, 3.4, 1.5, 0.4],\n",
       "        [5.2, 4.1, 1.5, 0.1],\n",
       "        [5.5, 4.2, 1.4, 0.2],\n",
       "        [4.9, 3.1, 1.5, 0.2],\n",
       "        [5. , 3.2, 1.2, 0.2],\n",
       "        [5.5, 3.5, 1.3, 0.2],\n",
       "        [4.9, 3.6, 1.4, 0.1],\n",
       "        [4.4, 3. , 1.3, 0.2],\n",
       "        [5.1, 3.4, 1.5, 0.2],\n",
       "        [5. , 3.5, 1.3, 0.3],\n",
       "        [4.5, 2.3, 1.3, 0.3],\n",
       "        [4.4, 3.2, 1.3, 0.2],\n",
       "        [5. , 3.5, 1.6, 0.6],\n",
       "        [5.1, 3.8, 1.9, 0.4],\n",
       "        [4.8, 3. , 1.4, 0.3],\n",
       "        [5.1, 3.8, 1.6, 0.2],\n",
       "        [4.6, 3.2, 1.4, 0.2],\n",
       "        [5.3, 3.7, 1.5, 0.2],\n",
       "        [5. , 3.3, 1.4, 0.2],\n",
       "        [7. , 3.2, 4.7, 1.4],\n",
       "        [6.4, 3.2, 4.5, 1.5],\n",
       "        [6.9, 3.1, 4.9, 1.5],\n",
       "        [5.5, 2.3, 4. , 1.3],\n",
       "        [6.5, 2.8, 4.6, 1.5],\n",
       "        [5.7, 2.8, 4.5, 1.3],\n",
       "        [6.3, 3.3, 4.7, 1.6],\n",
       "        [4.9, 2.4, 3.3, 1. ],\n",
       "        [6.6, 2.9, 4.6, 1.3],\n",
       "        [5.2, 2.7, 3.9, 1.4],\n",
       "        [5. , 2. , 3.5, 1. ],\n",
       "        [5.9, 3. , 4.2, 1.5],\n",
       "        [6. , 2.2, 4. , 1. ],\n",
       "        [6.1, 2.9, 4.7, 1.4],\n",
       "        [5.6, 2.9, 3.6, 1.3],\n",
       "        [6.7, 3.1, 4.4, 1.4],\n",
       "        [5.6, 3. , 4.5, 1.5],\n",
       "        [5.8, 2.7, 4.1, 1. ],\n",
       "        [6.2, 2.2, 4.5, 1.5],\n",
       "        [5.6, 2.5, 3.9, 1.1],\n",
       "        [5.9, 3.2, 4.8, 1.8],\n",
       "        [6.1, 2.8, 4. , 1.3],\n",
       "        [6.3, 2.5, 4.9, 1.5],\n",
       "        [6.1, 2.8, 4.7, 1.2],\n",
       "        [6.4, 2.9, 4.3, 1.3],\n",
       "        [6.6, 3. , 4.4, 1.4],\n",
       "        [6.8, 2.8, 4.8, 1.4],\n",
       "        [6.7, 3. , 5. , 1.7],\n",
       "        [6. , 2.9, 4.5, 1.5],\n",
       "        [5.7, 2.6, 3.5, 1. ],\n",
       "        [5.5, 2.4, 3.8, 1.1],\n",
       "        [5.5, 2.4, 3.7, 1. ],\n",
       "        [5.8, 2.7, 3.9, 1.2],\n",
       "        [6. , 2.7, 5.1, 1.6],\n",
       "        [5.4, 3. , 4.5, 1.5],\n",
       "        [6. , 3.4, 4.5, 1.6],\n",
       "        [6.7, 3.1, 4.7, 1.5],\n",
       "        [6.3, 2.3, 4.4, 1.3],\n",
       "        [5.6, 3. , 4.1, 1.3],\n",
       "        [5.5, 2.5, 4. , 1.3],\n",
       "        [5.5, 2.6, 4.4, 1.2],\n",
       "        [6.1, 3. , 4.6, 1.4],\n",
       "        [5.8, 2.6, 4. , 1.2],\n",
       "        [5. , 2.3, 3.3, 1. ],\n",
       "        [5.6, 2.7, 4.2, 1.3],\n",
       "        [5.7, 3. , 4.2, 1.2],\n",
       "        [5.7, 2.9, 4.2, 1.3],\n",
       "        [6.2, 2.9, 4.3, 1.3],\n",
       "        [5.1, 2.5, 3. , 1.1],\n",
       "        [5.7, 2.8, 4.1, 1.3],\n",
       "        [6.3, 3.3, 6. , 2.5],\n",
       "        [5.8, 2.7, 5.1, 1.9],\n",
       "        [7.1, 3. , 5.9, 2.1],\n",
       "        [6.3, 2.9, 5.6, 1.8],\n",
       "        [6.5, 3. , 5.8, 2.2],\n",
       "        [7.6, 3. , 6.6, 2.1],\n",
       "        [4.9, 2.5, 4.5, 1.7],\n",
       "        [7.3, 2.9, 6.3, 1.8],\n",
       "        [6.7, 2.5, 5.8, 1.8],\n",
       "        [7.2, 3.6, 6.1, 2.5],\n",
       "        [6.5, 3.2, 5.1, 2. ],\n",
       "        [6.4, 2.7, 5.3, 1.9],\n",
       "        [6.8, 3. , 5.5, 2.1],\n",
       "        [5.7, 2.5, 5. , 2. ],\n",
       "        [5.8, 2.8, 5.1, 2.4],\n",
       "        [6.4, 3.2, 5.3, 2.3],\n",
       "        [6.5, 3. , 5.5, 1.8],\n",
       "        [7.7, 3.8, 6.7, 2.2],\n",
       "        [7.7, 2.6, 6.9, 2.3],\n",
       "        [6. , 2.2, 5. , 1.5],\n",
       "        [6.9, 3.2, 5.7, 2.3],\n",
       "        [5.6, 2.8, 4.9, 2. ],\n",
       "        [7.7, 2.8, 6.7, 2. ],\n",
       "        [6.3, 2.7, 4.9, 1.8],\n",
       "        [6.7, 3.3, 5.7, 2.1],\n",
       "        [7.2, 3.2, 6. , 1.8],\n",
       "        [6.2, 2.8, 4.8, 1.8],\n",
       "        [6.1, 3. , 4.9, 1.8],\n",
       "        [6.4, 2.8, 5.6, 2.1],\n",
       "        [7.2, 3. , 5.8, 1.6],\n",
       "        [7.4, 2.8, 6.1, 1.9],\n",
       "        [7.9, 3.8, 6.4, 2. ],\n",
       "        [6.4, 2.8, 5.6, 2.2],\n",
       "        [6.3, 2.8, 5.1, 1.5],\n",
       "        [6.1, 2.6, 5.6, 1.4],\n",
       "        [7.7, 3. , 6.1, 2.3],\n",
       "        [6.3, 3.4, 5.6, 2.4],\n",
       "        [6.4, 3.1, 5.5, 1.8],\n",
       "        [6. , 3. , 4.8, 1.8],\n",
       "        [6.9, 3.1, 5.4, 2.1],\n",
       "        [6.7, 3.1, 5.6, 2.4],\n",
       "        [6.9, 3.1, 5.1, 2.3],\n",
       "        [5.8, 2.7, 5.1, 1.9],\n",
       "        [6.8, 3.2, 5.9, 2.3],\n",
       "        [6.7, 3.3, 5.7, 2.5],\n",
       "        [6.7, 3. , 5.2, 2.3],\n",
       "        [6.3, 2.5, 5. , 1.9],\n",
       "        [6.5, 3. , 5.2, 2. ],\n",
       "        [6.2, 3.4, 5.4, 2.3],\n",
       "        [5.9, 3. , 5.1, 1.8]]),\n",
       " 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]),\n",
       " 'frame': None,\n",
       " 'target_names': array(['setosa', 'versicolor', 'virginica'], dtype='<U10'),\n",
       " 'DESCR': '.. _iris_dataset:\\n\\nIris plants dataset\\n--------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 150 (50 in each of three classes)\\n    :Number of Attributes: 4 numeric, predictive attributes and the class\\n    :Attribute Information:\\n        - sepal length in cm\\n        - sepal width in cm\\n        - petal length in cm\\n        - petal width in cm\\n        - class:\\n                - Iris-Setosa\\n                - Iris-Versicolour\\n                - Iris-Virginica\\n                \\n    :Summary Statistics:\\n\\n    ============== ==== ==== ======= ===== ====================\\n                    Min  Max   Mean    SD   Class Correlation\\n    ============== ==== ==== ======= ===== ====================\\n    sepal length:   4.3  7.9   5.84   0.83    0.7826\\n    sepal width:    2.0  4.4   3.05   0.43   -0.4194\\n    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\\n    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\\n    ============== ==== ==== ======= ===== ====================\\n\\n    :Missing Attribute Values: None\\n    :Class Distribution: 33.3% for each of 3 classes.\\n    :Creator: R.A. Fisher\\n    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\\n    :Date: July, 1988\\n\\nThe famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\\nfrom Fisher\\'s paper. Note that it\\'s the same as in R, but not as in the UCI\\nMachine Learning Repository, which has two wrong data points.\\n\\nThis is perhaps the best known database to be found in the\\npattern recognition literature.  Fisher\\'s paper is a classic in the field and\\nis referenced frequently to this day.  (See Duda & Hart, for example.)  The\\ndata set contains 3 classes of 50 instances each, where each class refers to a\\ntype of iris plant.  One class is linearly separable from the other 2; the\\nlatter are NOT linearly separable from each other.\\n\\n|details-start|\\n**References**\\n|details-split|\\n\\n- Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\\n  Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\\n  Mathematical Statistics\" (John Wiley, NY, 1950).\\n- Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\\n  (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\\n- Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\\n  Structure and Classification Rule for Recognition in Partially Exposed\\n  Environments\".  IEEE Transactions on Pattern Analysis and Machine\\n  Intelligence, Vol. PAMI-2, No. 1, 67-71.\\n- Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\\n  on Information Theory, May 1972, 431-433.\\n- See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\\n  conceptual clustering system finds 3 classes in the data.\\n- Many, many more ...\\n\\n|details-end|',\n",
       " 'feature_names': ['sepal length (cm)',\n",
       "  'sepal width (cm)',\n",
       "  'petal length (cm)',\n",
       "  'petal width (cm)'],\n",
       " 'filename': 'iris.csv',\n",
       " 'data_module': 'sklearn.datasets.data'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#los modelos son lineas\n",
    "#datos continuos = modelos de regresion\n",
    "#datos discretos = modelos de clasificacion\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 4)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into 80% training and 20% testing (se seleccionan filas al azar)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "#random_state = siempre voy a eliminar las filas de forma aleatoria, pero siempre las mismas filas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((120, 4), (30, 4))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Create the k-NN classifier\n",
    "knn = KNeighborsClassifier(n_neighbors=3) #dividimos el espacio en tres clases diferentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier(n_neighbors=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier(n_neighbors=3)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=3)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the classifier on the training data\n",
    "knn.fit(X_train, y_train) #dadas estas carecteristicas de iris, dime si es setosa, versicolor o virginica)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "y_example = np.array([6.1, 2.8, 4.7, 1.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1, 0, 2, 1, 1, 0, 1, 2, 1, 1, 2, 0, 0, 0, 0, 1, 2, 1, 1, 2, 0, 2,\n",
       "        0, 2, 2, 2, 2, 2, 0, 0]),\n",
       " array([1, 0, 2, 1, 1, 0, 1, 2, 1, 1, 2, 0, 0, 0, 0, 1, 2, 1, 1, 2, 0, 2,\n",
       "        0, 2, 2, 2, 2, 2, 0, 0]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = knn.predict(X_test)\n",
    "y_pred, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#y_pred vs y_test\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       1.00      1.00      1.00         9\n",
      "           2       1.00      1.00      1.00        11\n",
      "\n",
      "    accuracy                           1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt=\"d\", cmap=\"YlGnBu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 1.0\n",
      "classification               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        14\n",
      "           1       1.00      1.00      1.00        22\n",
      "\n",
      "    accuracy                           1.00        36\n",
      "   macro avg       1.00      1.00      1.00        36\n",
      "weighted avg       1.00      1.00      1.00        36\n",
      "\n",
      "confusion [[14  0]\n",
      " [ 0 22]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy\", accuracy)\n",
    "\n",
    "# Generate a classification report\n",
    "classification = classification_report(y_test, y_pred)\n",
    "print(\"classification\", classification)\n",
    "\n",
    "# Generate a confusion matrix\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "print(\"confusion\", confusion)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Hunt for Lord Vinum's Elixir Wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>malic_acid</th>\n",
       "      <th>ash</th>\n",
       "      <th>alcalinity_of_ash</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>total_phenols</th>\n",
       "      <th>flavanoids</th>\n",
       "      <th>nonflavanoid_phenols</th>\n",
       "      <th>proanthocyanins</th>\n",
       "      <th>color_intensity</th>\n",
       "      <th>hue</th>\n",
       "      <th>od280/od315_of_diluted_wines</th>\n",
       "      <th>proline</th>\n",
       "      <th>wine_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113.0</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n",
       "0    14.23        1.71  2.43               15.6      127.0           2.80   \n",
       "1    13.20        1.78  2.14               11.2      100.0           2.65   \n",
       "2    13.16        2.36  2.67               18.6      101.0           2.80   \n",
       "3    14.37        1.95  2.50               16.8      113.0           3.85   \n",
       "4    13.24        2.59  2.87               21.0      118.0           2.80   \n",
       "\n",
       "   flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
       "0        3.06                  0.28             2.29             5.64  1.04   \n",
       "1        2.76                  0.26             1.28             4.38  1.05   \n",
       "2        3.24                  0.30             2.81             5.68  1.03   \n",
       "3        3.49                  0.24             2.18             7.80  0.86   \n",
       "4        2.69                  0.39             1.82             4.32  1.04   \n",
       "\n",
       "   od280/od315_of_diluted_wines  proline  wine_type  \n",
       "0                          3.92   1065.0          0  \n",
       "1                          3.40   1050.0          0  \n",
       "2                          3.17   1185.0          0  \n",
       "3                          3.45   1480.0          0  \n",
       "4                          2.93    735.0          0  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "import pandas as pd\n",
    "\n",
    "# The age-old Wine Scroll that holds secrets of the wines\n",
    "wine = datasets.load_wine()\n",
    "df = pd.DataFrame(wine.data, columns=wine.feature_names) #usamos pandas para cargar los datos en formato excel\n",
    "df['wine_type'] = [0 if i == 0 else 1 for i in wine.target]  # 0: Regular Wine, 1: Elixir Wine\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dejamos unos vinos para entrenarr, y otros para probar y evaluar\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.drop('wine_type', axis=1) #todas las columnas menos las de tipo\n",
    "y = df['wine_type'] #variable a predecir\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# x=variables entrenamientos y=resultados test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/myenv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#LogisticRegression se usa para problemas de clasificacion binaria\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 1.0\n",
      "precision 1.0\n",
      "recall 1.0\n",
      "f1 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(\"accuracy\", accuracy)\n",
    "\n",
    "precision = precision_score(y_test, y_pred)\n",
    "print(\"precision\", precision)\n",
    "\n",
    "recall = recall_score(y_test, y_pred)\n",
    "print(\"recall\", recall)\n",
    "\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(\"f1\", f1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
